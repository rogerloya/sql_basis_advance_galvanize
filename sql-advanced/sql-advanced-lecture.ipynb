{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced SQL\n",
    "\n",
    "## Lecture Objectives\n",
    "\n",
    "#### Part 1 SQL with python (psycopg2):\n",
    "\n",
    "- Connect to a database from within a python program and run queries\n",
    "- Understand psycopg2's cursors and commits\n",
    "- Generate dynamic queries\n",
    "\n",
    "#### Part 2 RDBMS the why and how:\n",
    "\n",
    " - Why an RDBMS?\n",
    " - The database lifecycle (and where the data scientist fits!)\n",
    " - Primary keys, foriegn keys, and the ERD\n",
    " - Creating and maintaining tables\n",
    " - Order of Evaluation of a SQL SELECT Statement\n",
    " - Transactions\n",
    " - SQL Execution Plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 Combining SQL and Python\n",
    "\n",
    "Often you will find yourself working with data that are only accessable through SQL.  However, your machine-learning capabilities are built in Python.  To resolve this issue, we can simply set up a connection from Python to the SQL database to bring the data to us."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why do we care?\n",
    "\n",
    "- SQL-based databases are extremely common in almost all industry environments\n",
    "- Can leverage the benefit of SQL's structure and scalability, while maintaining the flexibility of Python\n",
    "- Very useful for scaled data pipelines, pre-cleaning, data exploration\n",
    "- Allows for dynamic query generation and hence automations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## psycopg2\n",
    "\n",
    "- A Python library that allows for connections with PostgresSQL databases to easily query and retrieve data for analysis.\n",
    "- [Documentation--Includes Installation Instructions](http://initd.org/psycopg/docs/install.html)\n",
    "- In addition to what's listed in the documentation, if you have the anaconda distribution of Python \n",
    "- There are similar packages for other flavors of SQL that work much the same way\n",
    "\n",
    "To install using anaconda try \\\n",
    "`conda install psycopg2`\\\n",
    "If that does not work for your environment try:\\\n",
    "`pip install psycopg2-binary`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Workflow\n",
    "\n",
    "1. Establish connection to Postgres database using psycopg2\n",
    "2. Create a cursor\n",
    "3. Use the cursor to execute SQL queries and retrieve data\n",
    "4. Commit SQL actions\n",
    "4. Close the cursor and connection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Walkthrough 1: Creating a database from Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to the database\n",
    "- Connections must be established using an existing database, username, database IP/URL, and maybe passwords\n",
    "- If you need to create a database, you can first connect to Postgres using the dbname 'postgres' to initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-12T08:58:08.165520",
     "start_time": "2017-01-12T08:58:08.091308"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "conn = psycopg2.connect(dbname='postgres', host='localhost',user= 'postgres', password='galvanize')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate the Cursor\n",
    "\n",
    "- A cursor is a control structure that enables traversal over the records in a database\n",
    "- Executes and fetches data\n",
    "- When the cursor points at the resulting output of a query, it can only read each observation once.  If you choose to see a previously read observation, you must rerun the query. \n",
    "- Can be closed without closing the connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-12T08:58:08.185336",
     "start_time": "2017-01-12T08:58:08.167694"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Commits\n",
    "\n",
    "- Data changes are not actually stored until you choose to commit\n",
    "- You can choose to have automatic commit by using ` autocommit = True`\n",
    "- When connecting directly to the Postgres Server to initiate server level commands such as creating a database, you must use the `autocommit = True` option since Postgres does not have \"temporary\" transactions at the database level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-12T08:58:08.202928",
     "start_time": "2017-01-12T08:58:08.186623"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "conn.autocommit = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Create a database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-12T08:58:08.896355",
     "start_time": "2017-01-12T08:58:08.204962"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "cur.execute('DROP DATABASE IF EXISTS temp;')\n",
    "cur.execute('CREATE DATABASE temp;')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disconnect from the cursor and database\n",
    "- Cursors and Connections must be closed using .close() or else Postgres will lock certain operation on the database/tables to connection is severed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-12T08:58:08.919493",
     "start_time": "2017-01-12T08:58:08.898352"
    }
   },
   "outputs": [],
   "source": [
    "cur.close() # This is optional\n",
    "conn.close() # Closing the connection also closes all cursors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Walkthrough 2: Using the new database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to our database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-12T08:58:08.974359",
     "start_time": "2017-01-12T08:58:08.921473"
    }
   },
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(dbname='temp', host='localhost', user = 'postgres', password='galvanize')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-12T08:58:08.996294",
     "start_time": "2017-01-12T08:58:08.976269"
    }
   },
   "outputs": [],
   "source": [
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a new table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-12T08:58:09.021315",
     "start_time": "2017-01-12T08:58:08.998262"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "query = '''\n",
    "        CREATE TABLE logins (\n",
    "            userid integer, \n",
    "            tmstmp timestamp, \n",
    "            type varchar(10)\n",
    "        );\n",
    "        '''\n",
    "cur.execute(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert data into new table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`os` is needed to get the current directory and, later, dynamically identify the files we need to insert using listdir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-12T08:58:09.043481",
     "start_time": "2017-01-12T08:58:09.023639"
    }
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-12T08:58:09.069798",
     "start_time": "2017-01-12T08:58:09.045398"
    }
   },
   "outputs": [],
   "source": [
    "path = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-12T08:58:09.099361",
     "start_time": "2017-01-12T08:58:09.071953"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/skylarenglish/galvanize/lectures/sql-advanced'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-12T08:58:09.189981",
     "start_time": "2017-01-12T08:58:09.101617"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        COPY logins \n",
      "        FROM '/home/data/sql-advanced/logins_data/logins01.csv' \n",
      "        DELIMITER ',' \n",
      "        CSV;\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "query = '''\n",
    "        COPY logins \n",
    "        FROM '/home/data/sql-advanced/logins_data/logins01.csv' \n",
    "        DELIMITER ',' \n",
    "        CSV;\n",
    "        '''.format(path)\n",
    "print(query)\n",
    "cur.execute(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run a query to get 30 records from our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-12T08:58:09.226774",
     "start_time": "2017-01-12T08:58:09.192623"
    }
   },
   "outputs": [],
   "source": [
    "query = '''\n",
    "        SELECT *\n",
    "        FROM logins\n",
    "        LIMIT 30;\n",
    "        '''\n",
    "cur.execute(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets look at our data one line at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-12T08:58:09.259809",
     "start_time": "2017-01-12T08:58:09.230102"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(579, datetime.datetime(2013, 11, 20, 3, 20, 6), 'mobile')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur.fetchone()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Many lines at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-12T08:58:09.281025",
     "start_time": "2017-01-12T08:58:09.261857"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(823, datetime.datetime(2013, 11, 20, 3, 20, 49), 'web'),\n",
       " (953, datetime.datetime(2013, 11, 20, 3, 28, 49), 'web'),\n",
       " (612, datetime.datetime(2013, 11, 20, 3, 36, 55), 'web'),\n",
       " (269, datetime.datetime(2013, 11, 20, 3, 43, 13), 'web'),\n",
       " (799, datetime.datetime(2013, 11, 20, 3, 56, 55), 'web'),\n",
       " (890, datetime.datetime(2013, 11, 20, 4, 2, 33), 'mobile'),\n",
       " (330, datetime.datetime(2013, 11, 20, 4, 54, 59), 'mobile'),\n",
       " (628, datetime.datetime(2013, 11, 20, 4, 57, 22), 'mobile'),\n",
       " (398, datetime.datetime(2013, 11, 20, 5, 3, 19), 'mobile'),\n",
       " (482, datetime.datetime(2013, 11, 20, 5, 4, 43), 'mobile')]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fetchmany(n) to get n rows\n",
    "cur.fetchmany(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Or everything at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-12T08:58:09.308550",
     "start_time": "2017-01-12T08:58:09.284019"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#fetchall() grabs all remaining rows\n",
    "results = cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-12T08:58:09.340242",
     "start_time": "2017-01-12T08:58:09.309710"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-12T08:58:09.377396",
     "start_time": "2017-01-12T08:58:09.342447"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "[(581, datetime.datetime(2013, 11, 20, 5, 12, 3), 'mobile'), (370, datetime.datetime(2013, 11, 20, 5, 26, 46), 'mobile'), (230, datetime.datetime(2013, 11, 20, 5, 28, 29), 'web'), (596, datetime.datetime(2013, 11, 20, 5, 28, 36), 'web'), (274, datetime.datetime(2013, 11, 20, 5, 43, 8), 'mobile'), (581, datetime.datetime(2013, 11, 20, 5, 47, 10), 'web'), (417, datetime.datetime(2013, 11, 20, 5, 54, 37), 'mobile'), (185, datetime.datetime(2013, 11, 20, 5, 56, 22), 'mobile'), (371, datetime.datetime(2013, 11, 20, 5, 58, 35), 'mobile'), (133, datetime.datetime(2013, 11, 20, 5, 59, 7), 'web'), (621, datetime.datetime(2013, 11, 20, 6, 1, 46), 'web'), (306, datetime.datetime(2013, 11, 20, 6, 3, 23), 'mobile'), (509, datetime.datetime(2013, 11, 20, 6, 4, 43), 'web'), (505, datetime.datetime(2013, 11, 20, 6, 9, 52), 'web'), (678, datetime.datetime(2013, 11, 20, 6, 34, 18), 'web'), (889, datetime.datetime(2013, 11, 20, 6, 36, 32), 'mobile'), (202, datetime.datetime(2013, 11, 20, 6, 43, 33), 'mobile'), (614, datetime.datetime(2013, 11, 20, 6, 47, 55), 'mobile'), (882, datetime.datetime(2013, 11, 20, 6, 49), 'mobile')]\n"
     ]
    }
   ],
   "source": [
    "type(results[0])\n",
    "print(len(results))\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cur.scroll(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You can even iterate over the cursor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-12T08:58:09.417730",
     "start_time": "2017-01-12T08:58:09.380019"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2013-11-20 03:20:06: user 579 logged in via mobile\n",
      "2013-11-20 03:20:49: user 823 logged in via web\n",
      "2013-11-20 03:28:49: user 953 logged in via web\n",
      "2013-11-20 03:36:55: user 612 logged in via web\n",
      "2013-11-20 03:43:13: user 269 logged in via web\n",
      "2013-11-20 03:56:55: user 799 logged in via web\n",
      "2013-11-20 04:02:33: user 890 logged in via mobile\n",
      "2013-11-20 04:54:59: user 330 logged in via mobile\n",
      "2013-11-20 04:57:22: user 628 logged in via mobile\n",
      "2013-11-20 05:03:19: user 398 logged in via mobile\n",
      "2013-11-20 05:04:43: user 482 logged in via mobile\n",
      "2013-11-20 05:12:03: user 581 logged in via mobile\n",
      "2013-11-20 05:26:46: user 370 logged in via mobile\n",
      "2013-11-20 05:28:29: user 230 logged in via web\n",
      "2013-11-20 05:28:36: user 596 logged in via web\n",
      "2013-11-20 05:43:08: user 274 logged in via mobile\n",
      "2013-11-20 05:47:10: user 581 logged in via web\n",
      "2013-11-20 05:54:37: user 417 logged in via mobile\n",
      "2013-11-20 05:56:22: user 185 logged in via mobile\n",
      "2013-11-20 05:58:35: user 371 logged in via mobile\n",
      "2013-11-20 05:59:07: user 133 logged in via web\n",
      "2013-11-20 06:01:46: user 621 logged in via web\n",
      "2013-11-20 06:03:23: user 306 logged in via mobile\n",
      "2013-11-20 06:04:43: user 509 logged in via web\n",
      "2013-11-20 06:09:52: user 505 logged in via web\n",
      "2013-11-20 06:34:18: user 678 logged in via web\n",
      "2013-11-20 06:36:32: user 889 logged in via mobile\n",
      "2013-11-20 06:43:33: user 202 logged in via mobile\n",
      "2013-11-20 06:47:55: user 614 logged in via mobile\n",
      "2013-11-20 06:49:00: user 882 logged in via mobile\n"
     ]
    }
   ],
   "source": [
    "cur.execute(query)\n",
    "for record in cur:\n",
    "    print(\"{}: user {} logged in via {}\".format(record[1], record[0], record[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dynamic Queries\n",
    "\n",
    "- A Dynamic Query is a query that generates based on context.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example\n",
    "\n",
    "We have 8 login csv files that we need to insert into the logins table.  Instead of doing a COPY FROM query 8 times, we should utilize Python (or any future languages) to make this more efficient.  This is possible due to tokenized strings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First lets get an idea of how many records we start with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-12T08:58:09.446430",
     "start_time": "2017-01-12T08:58:09.421547"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "cur.execute('SELECT count(*) FROM logins;')\n",
    "record_count = cur.fetchone()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-12T08:58:09.471580",
     "start_time": "2017-01-12T08:58:09.451032"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-12T08:58:09.515994",
     "start_time": "2017-01-12T08:58:09.476168"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(record_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a query template and determine file path for imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## **[WARNING: BEWARE OF SQL INJECTION](http://initd.org/psycopg/docs/usage.html)**\n",
    "\n",
    "### What is an SQL Injection Attack?\n",
    "\n",
    "from W3schools.com:\n",
    "\n",
    " - SQL injection is a code injection technique that might destroy your database.\n",
    " - SQL injection is **one of the most common** web hacking techniques.\n",
    " - SQL injection is the placement of malicious code in SQL statements, via web page input.\n",
    " \n",
    "SQL injection usually occurs when you ask a user for input, like their username/userid, and instead of a name/id, the user gives you an SQL statement that you will **unknowingly run on your database.**\n",
    "\n",
    "Here is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-12T08:58:09.596979",
     "start_time": "2017-01-12T08:58:09.573540"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT * FROM logins WHERE tmstmp > 2014-08-01; DROP TABLE logins;\n"
     ]
    }
   ],
   "source": [
    "date_cut = \"2014-08-01; DROP TABLE logins\" # The user enters a date in a field on a web form\n",
    "\n",
    "horribly_risky = \"SELECT * FROM logins WHERE tmstmp > %s;\" % date_cut\n",
    "\n",
    "print(horribly_risky)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid SQL Injections **NEVER** use + or % or .format to reformat strings to be used with .execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-12T08:58:09.571188",
     "start_time": "2017-01-12T08:58:09.521349"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT * FROM logins WHERE userid = 579;\n",
      "SELECT * FROM logins WHERE tmstmp > 2014-08-01;\n"
     ]
    }
   ],
   "source": [
    "num = 579\n",
    "terribly_unsafe = \"SELECT * FROM logins WHERE userid = \" + str(num) + \";\"\n",
    "print(terribly_unsafe)\n",
    "\n",
    "\n",
    "date_cut = \"2014-08-01\"\n",
    "horribly_risky = \"SELECT * FROM logins WHERE tmstmp > %s;\" % date_cut\n",
    "print(horribly_risky)\n",
    "## Python is happy, but if num or date_cut included something malicious\n",
    "## your data could be at risk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now back to our query template and determine file path for imports\n",
    "\n",
    "### Practice safe SQL with Psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-12T08:58:09.614272",
     "start_time": "2017-01-12T08:58:09.599957"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "query = '''\n",
    "        COPY logins \n",
    "        FROM %(file_path)s\n",
    "        DELIMITER ','\n",
    "        CSV;\n",
    "        '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-12T08:58:10.030936",
     "start_time": "2017-01-12T08:58:09.615754"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logins08.csv inserted into table.\n",
      "logins06.csv inserted into table.\n",
      "logins07.csv inserted into table.\n",
      "logins05.csv inserted into table.\n",
      "logins04.csv inserted into table.\n",
      "logins03.csv inserted into table.\n",
      "logins02.csv inserted into table.\n"
     ]
    }
   ],
   "source": [
    "path = os.getcwd()\n",
    "folder_path = '/home/data/sql-advanced/logins_data/'\n",
    "for file_name in os.listdir('./logins_data'):\n",
    "    if file_name.endswith('.csv') and file_name != 'logins01.csv':\n",
    "        file_path=folder_path+file_name\n",
    "        cur.execute(query, {'file_path':file_path})\n",
    "        print('{0} inserted into table.'.format(file_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use .execute the corrent way, see how in the query string we used \n",
    "`%(file_path)s`\\\n",
    "Then in the `.execute()` method we used `{'file_path':file_path}` as a parameter\n",
    "\n",
    "\n",
    "#### For more on SQL injections check out [bobby-tables.com](http://www.bobby-tables.com/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, Let's check the total number of records we have right now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-12T08:58:10.065091",
     "start_time": "2017-01-12T08:58:10.033034"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old record count: 10000\n",
      "New record count: 78588\n"
     ]
    }
   ],
   "source": [
    "print(\"Old record count: {}\".format(record_count))\n",
    "\n",
    "cur.execute('SELECT count(*) FROM logins;')\n",
    "record_count = cur.fetchone()[0]\n",
    "\n",
    "print(\"New record count: {}\".format(record_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-12T08:57:22.334048",
     "start_time": "2017-01-12T08:57:22.321062"
    }
   },
   "source": [
    "### Transactions can be rolled back until they're committed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-12T08:58:10.188575",
     "start_time": "2017-01-12T08:58:10.067757"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After rollback: 10000\n"
     ]
    }
   ],
   "source": [
    "conn.rollback()\n",
    "\n",
    "cur.execute('SELECT count(*) FROM logins;')\n",
    "record_count = cur.fetchone()[0]\n",
    "\n",
    "print(\"After rollback: {}\".format(record_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Don't forget to commit your changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-12T08:58:10.189096",
     "start_time": "2017-01-12T16:58:08.148Z"
    }
   },
   "outputs": [],
   "source": [
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Close your connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-12T08:58:10.189407",
     "start_time": "2017-01-12T16:58:08.149Z"
    }
   },
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using python `with` Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-12T08:58:10.189716",
     "start_time": "2017-01-12T16:58:08.151Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cursor inside with block: <cursor object at 0x107852a50; closed: 0>\n",
      "10000\n",
      "Cursor outside with block: <cursor object at 0x107852a50; closed: -1>\n"
     ]
    }
   ],
   "source": [
    "query = \"SELECT count(*) FROM logins;\"\n",
    "with psycopg2.connect(dbname='temp', host='localhost', user = 'postgres', password='galvanize') as conn:\n",
    "    with conn.cursor() as curs:\n",
    "        print(\"Cursor inside with block: {}\".format(curs))\n",
    "        curs.execute(query)\n",
    "        record_count = curs.fetchone()[0]\n",
    "        print(record_count)\n",
    "    print(\"Cursor outside with block: {}\".format(curs))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-12T08:51:21.531861",
     "start_time": "2017-01-12T08:51:21.518559"
    }
   },
   "source": [
    "### Note that the connection is *not* closed automatically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-12T08:58:10.189999",
     "start_time": "2017-01-12T16:58:08.153Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<connection object at 0x108529050; dsn: 'user=postgres password=xxx dbname=temp host=localhost', closed: 0>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-12T08:58:10.190294",
     "start_time": "2017-01-12T16:58:08.154Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<connection object at 0x108529050; dsn: 'user=postgres password=xxx dbname=temp host=localhost', closed: 1>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn.close()\n",
    "conn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Things to Remember about psycopg2\n",
    "\n",
    "* Connections must be established using an existing database, username, database IP/URL, and maybe passwords\n",
    "* If you have no created databases, you can connect to Postgres using the dbname 'postgres' to initialize db commands\n",
    "* Data changes are not actually stored until you choose to commit. This can be done either through `conn.commit()` or setting `autocommit = True`.  Until commited, all transactions is only temporary stored.\n",
    "* Autocommit = True is necessary to do database commands like CREATE DATABASE.  This is because Postgres does not have temporary transactions at the database level.\n",
    "* If you ever need to build similar pipelines for other forms of database, there are libraries such PyODBC which operate very similarly.\n",
    "* SQL connection databases utilizes cursors for data traversal and retrieval.  This is kind of like an iterator in Python.\n",
    "* Cursor operations typically goes like the following:\n",
    "    - execute a query\n",
    "    - fetch rows from query result if it is a SELECT query\n",
    "    - because it is iterative, previously fetched rows can only be fetched again by rerunning the query\n",
    "    - close cursor through .close()\n",
    "* Cursors and Connections must be closed using .close() or else Postgres will lock certain operation on the database/tables to connection is severed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 RDBMS the why and how:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relational Database Management System (RDBMS)\n",
    "\n",
    "#### It is a persistent data storage system\n",
    " - Schema defines the structure of a table or a database\n",
    " - Database is composed of a number of user-defined tables\n",
    " - Each table has columns (or fields) and rows (or records)\n",
    " - A column is of a certain data type such as an integer, text, or date\n",
    "\n",
    "With a new data source, your first task is typically to understand the schema. \n",
    "This will likely take time and conversations with those that gave you access to the database or its data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![RDBMS Diagram](img/RDBMS_Diagram.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RDBMS and SQL\n",
    "\n",
    " - SQL is the language used to query relational databases\n",
    " - **All RDBMS** use SQL and the syntax and keywords are the same for the most part, across systems\n",
    " - **SQL is used to interact** with RDBMS, allowing you to create tables, alter tables, insert records, update records, delete records, and query records within and across tables.\n",
    " - Even non-relational databases like **Hadoop** usually have a SQL-like interface available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Database Life Cycle (DBLC)\n",
    "\n",
    "![DBLC](img/DBLC_Diagram.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### An inefficient way to store data...\n",
    "\n",
    "##### A single table with records of customer purchases at an outdoor sports store.\n",
    "\n",
    "![Inefficient Table](img/Inefficient_Table.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Relational Database Management Systems\n",
    "\n",
    " - A RDBMS is a type of database where **data is stored in multiple related tables.**\n",
    " - The tables are related through **primary** and **foreign keys**.\n",
    " - The same information as shown before in an RDBMS:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Primary Keys\n",
    "\n",
    " - Every table in a RDBMS has a **primary key**  that uniquely identifies that row\n",
    " - Each entry must have a primary key, and primary keys cannot repeat within a table\n",
    " - Primary keys are usually integers, often [GUIDs or UUIDs](https://www.guidgenerator.com/online-guid-generator.aspx), but can take other forms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Foreign Keys and Table Relationships\n",
    "\n",
    " - A **foreign key** is a column that uniquely identifies a column in another table\n",
    " - Often, a foreign key in one table is a primary key in another table\n",
    " - We can use foreign keys to join tables\n",
    " \n",
    "  ![Foreign Key Diagram](img/Foreign_Key_Diagram.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entity Relationship Diagram (ERD)\n",
    "\n",
    "An Entity Relationship Diagram (ERD) represents how each forien key and primary key connects the tables. When using real production data, these diagrams can take up many pages.\n",
    "\n",
    "![ERD](img/ERD_Diagram.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Database Normalization\n",
    "\n",
    "##### Store each piece of information in exactly one place\n",
    " - Details about a user (address, age) are only stored once (in a users table)\n",
    " - Any other table (eg. purchases) where this data might be relevant, only references the user_id\n",
    " \n",
    "![RDBMS](img/RDBMS_Diagram.png)\n",
    "\n",
    "##### Why is this a good thing?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normal Forms\n",
    "\n",
    "Normalization is explained through *Normal forms*\n",
    "\n",
    " - 1st Normal Form: each attribute has a single value\n",
    " - 2nd Normal Form: no dependencies on part of a key\n",
    " - 3rd Normal Form: no transitive dependencies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Why Not Normalize?\n",
    "\n",
    "Sometimes databases are not fully normalized.\n",
    "\n",
    " - Data structure not known/may change\n",
    " - Writing a schema/converting data is hard\n",
    " - Simple queries are important\n",
    " - Data will not be changed/integrity not important\n",
    " - Storage is cheap\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![DLBC2](img/DBLC_Diagram2.jpg)\n",
    "#### Data Science in the DBLC\n",
    "\n",
    " - Data Science Operations: querying, aggregating\n",
    " - Data Science Implementation: identifying, cleaning, pushing external data sources inside a RDBMS\n",
    " - Data Science Design: recommendations on the model, specs on operations\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question:\n",
    "\n",
    "As a data scientist, what are the advantages of\n",
    "storing, querying, and maintaining data in a SQL database\n",
    "over curating your own flat files (e.g. csv files) ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a table with a schema\n",
    "\n",
    "![Create Table](img/create_table.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inserting values into a table\n",
    "\n",
    "![insert into table](img/Insert_into_table.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SQL Queries for table creation / maintenance\n",
    "\n",
    "Creating a table from query:\n",
    "```sql\n",
    "CREATE [TEMPORARY] TABLE table AS <SQL query>;\n",
    "```\n",
    "Inserting records in a table:\n",
    "```sql\n",
    "INSERT INTO table [(c1,c2,c3,…)] VALUES (v1,v2,v3,…);\n",
    "```\n",
    "Updating records:\n",
    "```sql\n",
    "UPDATE table SET c1=v1,c2=v2,… WHERE cX=vX;\n",
    "```\n",
    "Delete records:\n",
    "```sql\n",
    "DELETE FROM table WHERE cX=vX;\n",
    "```\n",
    "Change model (add, drop, modify columns):\n",
    "```sql\n",
    "ALTER TABLE table [DROP/ADD/ALTER] column [datatype];\n",
    "```\n",
    "Delete a table:\n",
    "```sql\n",
    "DROP TABLE table;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![DLBC](img/DBLC_Diagram.jpg)\n",
    "\n",
    "#### Question?\n",
    "\n",
    "How many rows would result in\n",
    "(inner join, left join, right join, full outer join) on `department_id` ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Order of Evaluation of a SQL SELECT Statement\n",
    "\n",
    "1. FROM + JOIN: first the product of all tables is formed\n",
    "2. WHERE: the where clause filters rows that do not meet the search condition\n",
    "3. GROUP BY + (COUNT, SUM, etc): the rows are grouped using the columns in the group by clause and the aggregation functions are applied on the grouping\n",
    "4. HAVING: like the WHERE clause, but can be applied after aggregation\n",
    "5. SELECT: the targeted list of columns are evaluated and returned\n",
    "6. DISTINCT: duplicate rows are eliminated\n",
    "7. ORDER BY: the resulting rows are sorted\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Order of Evaluation of a SQL SELECT Statement\n",
    "\n",
    "![Order of Evaluation](img/Order_of_Evaluation.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transactions\n",
    "\n",
    "Suppose you update multiple records in a single statement.\n",
    "One update fails.\n",
    "\\\n",
    "What should happen?\n",
    "\\\n",
    "What does happen?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Database statements can be groups into a transaction.\n",
    "End transaction with `commit` or `rollback`.\\\n",
    "Default interactive behavior is autocommit.\n",
    "\\\n",
    "\\\n",
    "**Transactions are:**\n",
    " - Atomic\n",
    " - Consistent\n",
    " - Isolated\n",
    " - Durable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Excecution Plan\n",
    "\n",
    "When troubleshooting a query, you may want to figure out what your query is in fact doing. Most SQL systems have their own internal query optomiser, so if the query you write is not in the most efficient form, the sql system will optomize it. Sometimes still your query will fail. You can use the Execution plan to troubleshoot this.\n",
    "\n",
    "![Exec](img/exec_plan.png)\n",
    "\n",
    "If you are concerned about running too large a query, you can run your execution plan prior to running the query. Running to large of a query may be hard to accomplish using the datasets you find online, but can be a real concern when working with real world data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lecture Objectives\n",
    "\n",
    "#### Part 1 SQL with python (psycopg2):\n",
    "\n",
    "- Connect to a database from within a python program and run queries\n",
    "- Understand psycopg2's cursors and commits\n",
    "- Generate dynamic queries\n",
    "\n",
    "#### Part 2 RDBMS the why and how:\n",
    "\n",
    " - Why an RDBMS?\n",
    " - The database lifecycle (and where the data scientist fits!)\n",
    " - Primary keys, foriegn keys, and the ERD\n",
    " - Creating and maintaining tables\n",
    " - Order of Evaluation of a SQL SELECT Statement\n",
    " - Transactions\n",
    " - SQL Execution Plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
